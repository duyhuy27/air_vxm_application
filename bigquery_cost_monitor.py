#!/usr/bin/env python3
"""
BigQuery Cost Monitor vÃ  Data Growth Tracker
Theo dÃµi chi phÃ­ vÃ  dá»± bÃ¡o tÄƒng trÆ°á»Ÿng dá»¯ liá»‡u
"""

import os
import sys
from datetime import datetime, timedelta
from google.cloud import bigquery
from google.oauth2 import service_account

def get_bigquery_client():
    """Khá»Ÿi táº¡o BigQuery client"""
    credentials_path = "credentials/invertible-now-462103-m3-c75684b0bb78.json"
    
    if not os.path.exists(credentials_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file credentials: {credentials_path}")
        return None
    
    credentials = service_account.Credentials.from_service_account_file(credentials_path)
    client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    return client

def analyze_data_growth():
    """PhÃ¢n tÃ­ch tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng dá»¯ liá»‡u thá»±c táº¿"""
    client = get_bigquery_client()
    if not client:
        return
    
    print("ğŸ“Š PHÃ‚N TÃCH Tá»C Äá»˜ TÄ‚NG TRÆ¯á»NG Dá»® LIá»†U")
    print("=" * 60)
    
    # Kiá»ƒm tra dá»¯ liá»‡u trong 7 ngÃ y gáº§n nháº¥t
    query = """
    SELECT 
        DATE(t.time) as date,
        COUNT(*) as daily_records,
        AVG(f.pm2_5) as avg_pm25,
        AVG(f.temperature_2m) as avg_temp
    FROM `invertible-now-462103-m3.weather_and_air_dataset.Fact_Weather_AirQuality` f
    JOIN `invertible-now-462103-m3.weather_and_air_dataset.Dim_Time` t
    ON f.time_key = t.time_key
    WHERE DATE(t.time) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
    GROUP BY DATE(t.time)
    ORDER BY date DESC
    """
    
    try:
        results = client.query(query).result()
        
        total_records = 0
        dates = []
        
        for row in results:
            print(f"ğŸ“… {row.date}: {row.daily_records:,} records, PM2.5: {row.avg_pm25:.1f}, Temp: {row.avg_temp:.1f}Â°C")
            total_records += row.daily_records
            dates.append(row.date)
        
        if len(dates) > 0:
            avg_daily_records = total_records / len(dates)
            print(f"\nğŸ“ˆ Trung bÃ¬nh: {avg_daily_records:.0f} records/ngÃ y")
            
            # Dá»± bÃ¡o based on actual data
            print(f"\nğŸ”® Dá»° BÃO Dá»°A TRÃŠN Dá»® LIá»†U THá»°C Táº¾:")
            periods = [
                ("1 thÃ¡ng", 30),
                ("1 nÄƒm", 365), 
                ("10 nÄƒm", 3650)
            ]
            
            current_size_gb = 0.63  # From previous analysis
            bytes_per_record = 300  # Estimated
            
            for period_name, days in periods:
                new_records = avg_daily_records * days
                new_size_gb = (new_records * bytes_per_record) / (1024**3)
                total_size_gb = current_size_gb + new_size_gb
                
                print(f"ğŸ“Š {period_name}: +{new_records:,.0f} records, +{new_size_gb:.2f} GB â†’ Tá»•ng: {total_size_gb:.2f} GB")
    
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

def calculate_storage_costs():
    """TÃ­nh toÃ¡n chi phÃ­ lÆ°u trá»¯ chi tiáº¿t"""
    client = get_bigquery_client()
    if not client:
        return
    
    print("\nğŸ’° PHÃ‚N TÃCH CHI PHÃ BIGQUERY CHI TIáº¾T")
    print("=" * 60)
    
    # Láº¥y thÃ´ng tin storage thá»±c táº¿
    query = """
    SELECT 
        table_id,
        ROUND(size_bytes / 1024 / 1024 / 1024, 4) as size_gb,
        row_count,
        ROUND(size_bytes / 1024 / 1024 / 1024 * 0.020, 4) as monthly_storage_cost_usd
    FROM `invertible-now-462103-m3.weather_and_air_dataset.__TABLES__`
    WHERE table_id IN ('Fact_Weather_AirQuality', 'Staging_RawData', 'Dim_Time', 'Dim_Location')
    ORDER BY size_bytes DESC
    """
    
    try:
        results = client.query(query).result()
        
        total_size = 0
        total_cost = 0
        
        print("ğŸ“‹ Chi phÃ­ theo báº£ng:")
        for row in results:
            print(f"   ğŸ“Š {row.table_id}: {row.size_gb} GB â†’ ${row.monthly_storage_cost_usd:.4f}/thÃ¡ng")
            total_size += row.size_gb
            total_cost += row.monthly_storage_cost_usd
        
        print(f"\nğŸ’¾ Tá»•ng storage: {total_size:.3f} GB")
        print(f"ğŸ’µ Chi phÃ­ storage hiá»‡n táº¡i: ${total_cost:.4f}/thÃ¡ng (${total_cost*12:.2f}/nÄƒm)")
        
        # Dá»± bÃ¡o chi phÃ­
        print(f"\nğŸ”® Dá»° BÃO CHI PHÃ:")
        growth_scenarios = [
            ("Conservative (hiá»‡n táº¡i)", 1.0),
            ("1 nÄƒm", 1.1),  # +10%
            ("5 nÄƒm", 1.5),  # +50% 
            ("10 nÄƒm", 2.0)  # +100%
        ]
        
        for scenario, multiplier in growth_scenarios:
            future_size = total_size * multiplier
            future_monthly_cost = future_size * 0.020
            future_yearly_cost = future_monthly_cost * 12
            print(f"   ğŸ“Š {scenario}: {future_size:.3f} GB â†’ ${future_monthly_cost:.4f}/thÃ¡ng (${future_yearly_cost:.2f}/nÄƒm)")
    
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

def query_cost_analysis():
    """PhÃ¢n tÃ­ch chi phÃ­ query"""
    print(f"\nğŸ” PHÃ‚N TÃCH CHI PHÃ QUERY")
    print("=" * 60)
    
    current_size_gb = 0.63
    query_cost_per_tb = 5.0  # $5 per TB
    
    print("ğŸ’¡ Chi phÃ­ query Æ°á»›c tÃ­nh:")
    query_types = [
        ("Full table scan", current_size_gb, 1.0),
        ("Date range query (1 thÃ¡ng)", current_size_gb * 0.08, 0.08),
        ("Location specific", current_size_gb * 0.03, 0.03),
        ("Aggregated dashboard", current_size_gb * 0.1, 0.1)
    ]
    
    for query_type, data_processed_gb, percentage in query_types:
        data_processed_tb = data_processed_gb / 1024
        cost = data_processed_tb * query_cost_per_tb
        print(f"   ğŸ“Š {query_type}: {data_processed_gb:.3f} GB â†’ ${cost:.5f}/query")
    
    print(f"\nğŸ“ˆ Vá»›i 1000 queries/thÃ¡ng (mix queries):")
    avg_cost_per_query = 0.0001  # Estimated average
    monthly_query_cost = avg_cost_per_query * 1000
    print(f"   ğŸ’µ Chi phÃ­ query: ~${monthly_query_cost:.2f}/thÃ¡ng")

def monitoring_recommendations():
    """ÄÆ°a ra khuyáº¿n nghá»‹ monitoring"""
    print(f"\nğŸš¨ KHUYáº¾N NGHá»Š MONITORING")
    print("=" * 60)
    
    recommendations = [
        "ğŸ”” Setup BigQuery quota alerts táº¡i 80% limit",
        "ğŸ“Š Monitor daily storage growth qua Cloud Monitoring", 
        "ğŸ’° Thiáº¿t láº­p budget alerts cho BigQuery costs",
        "ğŸ• Schedule weekly cost reports",
        "ğŸ“ˆ Track query performance vÃ  optimize slow queries",
        "ğŸ—‚ï¸  Implement table partitioning by date",
        "â„ï¸  Consider data archival policy sau 2-3 nÄƒm",
        "ğŸ” Use approximate aggregation cho large datasets"
    ]
    
    for rec in recommendations:
        print(f"   {rec}")
    
    print(f"\nâš™ï¸  SETUP COMMANDS:")
    print(f"   # Táº¡o budget alert")
    print(f"   gcloud billing budgets create --billing-account=BILLING_ID --amount=10 --display-name='BigQuery Budget'")
    print(f"   ")
    print(f"   # Setup monitoring")
    print(f"   gcloud logging sinks create bigquery-costs 'bigquery.googleapis.com/dml_statistics'")

def main():
    """Main function"""
    print("ğŸ” BIGQUERY COST MONITOR & DATA GROWTH TRACKER")
    print("=" * 70)
    print(f"ğŸ“… Thá»i gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    try:
        analyze_data_growth()
        calculate_storage_costs() 
        query_cost_analysis()
        monitoring_recommendations()
        
        print(f"\nâœ… HoÃ n thÃ nh phÃ¢n tÃ­ch cost monitor!")
        
    except Exception as e:
        print(f"âŒ Lá»—i tá»•ng quÃ¡t: {e}")

if __name__ == "__main__":
    main()
